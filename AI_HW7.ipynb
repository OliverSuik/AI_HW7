{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Input, GlobalAveragePooling2D, Dense, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Deconvolution2D\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for building the discriminator layers\n",
    "def build_discriminator(start_filters, spatial_dim, filter_size):\n",
    "    \n",
    "    # function for building a CNN block for downsampling the image\n",
    "    def add_discriminator_block(x, filters, filter_size):\n",
    "        x = Conv2D(filters, filter_size, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters, filter_size, padding='same', strides=2)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.3)(x)\n",
    "        return x\n",
    "    \n",
    "    # input is an image with shape spatial_dim x spatial_dim and 3 channels\n",
    "    inp = Input(shape=(spatial_dim, spatial_dim, 3))\n",
    "\n",
    "    # design the discrimitor to downsample the image 4x\n",
    "    x = add_discriminator_block(inp, start_filters, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 2, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 4, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 8, filter_size)\n",
    "    \n",
    "    # average and return a binary output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(start_filters, filter_size, latent_dim):\n",
    "      # function for building a CNN block for upsampling the image\n",
    "    def add_generator_block(x, filters, filter_size):\n",
    "        x = Deconvolution2D(filters, filter_size, strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.3)(x)\n",
    "        return x\n",
    "\n",
    "    # input is a noise vector \n",
    "    inp = Input(shape=(latent_dim,))\n",
    "\n",
    "    # projection of the noise vector into a tensor with \n",
    "    # same shape as last conv layer in discriminator\n",
    "    x = Dense(4 * 4 * (start_filters * 8), input_dim=latent_dim)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Reshape(target_shape=(4, 4, start_filters * 8))(x)\n",
    "\n",
    "    # design the generator to upsample the image 4x\n",
    "    x = add_generator_block(x, start_filters * 4, filter_size)\n",
    "    x = add_generator_block(x, start_filters * 2, filter_size)\n",
    "    x = add_generator_block(x, start_filters, filter_size)\n",
    "    x = add_generator_block(x, start_filters, filter_size)    \n",
    "\n",
    "    # turn the output into a 3D tensor, an image with 3 channels \n",
    "    x = Conv2D(3, kernel_size=5, padding='same', activation='tanh')(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 8, 8, 64)          204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 16, 16, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 32, 32, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 64, 64, 16)        6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 64, 64, 3)         1203      \n",
      "=================================================================\n",
      "Total params: 492,083\n",
      "Trainable params: 487,731\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n",
      "Model: \"functional_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 16)        1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 32, 32, 16)        6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 16, 16, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 816,529\n",
      "Trainable params: 0\n",
      "Non-trainable params: 816,529\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_11 (Functional)   (None, 64, 64, 3)         492083    \n",
      "_________________________________________________________________\n",
      "functional_9 (Functional)    (None, 1)                 816529    \n",
      "=================================================================\n",
      "Total params: 1,308,612\n",
      "Trainable params: 487,731\n",
      "Non-trainable params: 820,881\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load celebrity images attributes\n",
    "df_celeb = pd.read_csv('list_attr_celeba.csv')\n",
    "TOTAL_SAMPLES = df_celeb.shape[0]\n",
    "\n",
    "# we will downscale the images\n",
    "SPATIAL_DIM = 64 \n",
    "# size of noise vector\n",
    "LATENT_DIM_GAN = 100 \n",
    "# filter size in conv layer\n",
    "FILTER_SIZE = 5\n",
    "# number of filters in conv layer\n",
    "NET_CAPACITY = 16\n",
    "# batch size\n",
    "BATCH_SIZE_GAN = 32\n",
    "# interval for displaying generated images\n",
    "PROGRESS_INTERVAL = 80 \n",
    "# directory for storing generated images\n",
    "ROOT_DIR = 'visualization'\n",
    "if not os.path.isdir(ROOT_DIR):\n",
    "    os.mkdir(ROOT_DIR)\n",
    "    \n",
    "\n",
    "\n",
    "def construct_models(verbose=False):\n",
    "    ### discriminator\n",
    "    discriminator = build_discriminator(NET_CAPACITY, SPATIAL_DIM, FILTER_SIZE)\n",
    "    # compile discriminator\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002), metrics=['mae'])\n",
    "\n",
    "    ### generator\n",
    "    # do not compile generator\n",
    "    generator = build_generator(NET_CAPACITY, FILTER_SIZE, LATENT_DIM_GAN)\n",
    "\n",
    "    ### DCGAN \n",
    "    gan = Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "    discriminator.trainable = False \n",
    "    gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002), metrics=['mae'])\n",
    "\n",
    "    if verbose: \n",
    "        generator.summary()\n",
    "        discriminator.summary()\n",
    "        gan.summary()\n",
    "        \n",
    "    return generator, discriminator, gan\n",
    "  \n",
    "generator_celeb, discriminator_celeb, gan_celeb = construct_models(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for selecting 'size' real images\n",
    "# and downscaling them to lower dimension SPATIAL_DIM\n",
    "def get_real_celebrity(df, size, total):\n",
    "    cur_files = df.sample(frac=1).iloc[0:size]\n",
    "    X = np.empty(shape=(size, SPATIAL_DIM, SPATIAL_DIM, 3))\n",
    "    for i in range(0, size):\n",
    "        file = cur_files.iloc[i]\n",
    "        img_uri = 'img_align_celeba/img_align_celeba/' + file.image_id\n",
    "        img = cv2.imread(img_uri)\n",
    "        img = cv2.resize(img, (SPATIAL_DIM, SPATIAL_DIM))\n",
    "        img = np.flip(img, axis=2)\n",
    "        img = img.astype(np.float32) / 127.5 - 1.0\n",
    "        X[i] = img\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "im = Image.open(r\"img_align_celeba/000004.jpg\")\n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-fd448e0dbf4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m generator_celeb, discriminator_celeb, gan_celeb = run_training(generator_celeb, \n\u001b[0m\u001b[0;32m     86\u001b[0m                                                                \u001b[0mdiscriminator_celeb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                                                                \u001b[0mgan_celeb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-fd448e0dbf4b>\u001b[0m in \u001b[0;36mrun_training\u001b[1;34m(generator, discriminator, gan, df, start_it, num_epochs, get_real_images)\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE_GAN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLATENT_DIM_GAN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m               \u001b[1;31m# train the generator on fake images with label 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m           \u001b[1;31m# store loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1693\u001b[0m                                                     class_weight)\n\u001b[0;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    " \n",
    "# number of discriminator updates per alternating training iteration\n",
    "DISC_UPDATES = 1  \n",
    "# number of generator updates per alternating training iteration\n",
    "GEN_UPDATES = 1 \n",
    "\n",
    "# function for training a GAN\n",
    "def run_training(generator, discriminator, gan, df=df_celeb, start_it=0, num_epochs=1000, \n",
    "                 get_real_images=get_real_celebrity):\n",
    "  # list for storing loss\n",
    "    avg_loss_discriminator = []\n",
    "    avg_loss_generator = []\n",
    "    total_it = start_it\n",
    "\n",
    "  # main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "      # alternating training loop\n",
    "        loss_discriminator = []\n",
    "        loss_generator = []\n",
    "        for it in range(200): \n",
    "\n",
    "          #### Discriminator training loop ####\n",
    "            for i in range(DISC_UPDATES): \n",
    "              # select a random set of real images\n",
    "                imgs_real = get_real_images(df, BATCH_SIZE_GAN, TOTAL_SAMPLES)\n",
    "              # generate a set of random noise vectors\n",
    "                noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # generate a set of fake images using the generator\n",
    "                imgs_fake = generator.predict(noise)\n",
    "              # train the discriminator on real images with label 1\n",
    "                d_loss_real = discriminator.train_on_batch(imgs_real, np.ones([BATCH_SIZE_GAN]))[1]\n",
    "              # train the discriminator on fake images with label 0\n",
    "                d_loss_fake = discriminator.train_on_batch(imgs_fake, np.zeros([BATCH_SIZE_GAN]))[1]\n",
    "\n",
    "          # display some fake images for visual control of convergence\n",
    "            if total_it % PROGRESS_INTERVAL == 0:\n",
    "                plt.figure(figsize=(5,2))\n",
    "                num_vis = min(BATCH_SIZE_GAN, 5)\n",
    "                imgs_real = get_real_images(df, num_vis, TOTAL_SAMPLES)\n",
    "                noise = np.random.randn(num_vis, LATENT_DIM_GAN)\n",
    "                imgs_fake = generator.predict(noise)\n",
    "                for obj_plot in [imgs_fake, imgs_real]:\n",
    "                    plt.figure(figsize=(num_vis * 3, 3))\n",
    "                    for b in range(num_vis):\n",
    "                        disc_score = float(discriminator.predict(np.expand_dims(obj_plot[b], axis=0))[0])\n",
    "                        plt.subplot(1, num_vis, b + 1)\n",
    "                        plt.title(str(round(disc_score, 3)))\n",
    "                        plt.imshow(obj_plot[b] * 0.5 + 0.5) \n",
    "                    if obj_plot is imgs_fake:\n",
    "                        plt.savefig(os.path.join(ROOT_DIR, str(total_it).zfill(10) + '.jpg'), format='jpg', bbox_inches='tight')\n",
    "                    plt.show()  \n",
    "\n",
    "          #### Generator training loop ####\n",
    "            loss = 0\n",
    "            y = np.ones([BATCH_SIZE_GAN, 1]) \n",
    "            for j in range(GEN_UPDATES):\n",
    "              # generate a set of random noise vectors\n",
    "                noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # train the generator on fake images with label 1\n",
    "                loss += gan.train_on_batch(noise, y)[1]\n",
    "\n",
    "          # store loss\n",
    "            loss_discriminator.append((d_loss_real + d_loss_fake) / 2.)        \n",
    "            loss_generator.append(loss / GEN_UPDATES)\n",
    "            total_it += 1\n",
    "\n",
    "      # visualize loss\n",
    "        clear_output(True)\n",
    "        print('Epoch', epoch)\n",
    "        avg_loss_discriminator.append(np.mean(loss_discriminator))\n",
    "        avg_loss_generator.append(np.mean(loss_generator))\n",
    "        plt.plot(range(len(avg_loss_discriminator)), avg_loss_discriminator)\n",
    "        plt.plot(range(len(avg_loss_generator)), avg_loss_generator)\n",
    "        plt.legend(['discriminator loss', 'generator loss'])\n",
    "        plt.show()\n",
    "\n",
    "    return generator, discriminator, gan\n",
    "\n",
    "generator_celeb, discriminator_celeb, gan_celeb = run_training(generator_celeb, \n",
    "                                                               discriminator_celeb, \n",
    "                                                               gan_celeb, \n",
    "                                                               num_epochs=500, \n",
    "                                                               df=df_celeb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
